# Introduction-of-paper-KG_1  
This is introduction of paper "[Mning quality phrases from massive Text Corpora](https://dl.acm.org/doi/10.1145/2723372.2751523)"  
**摘要**  
文本数据（Text data）无处不在，并在大数据应用中起着至关重要的作用。然而，文本数据大多是非结构化的。将非结构化文本转化为结构化单元可以大大减少语义歧义，并易于数据库处理。因此，高质量短语的挖掘是数据库领域一个重要研究课题。本文提出了一种结合短语切分的文本语料库高质量短语提取框架。该框架只需要有限的训练，且这样生成的短语的质量接近于人类的判断。此外，该方法具有可扩展性：计算时间和所需空间均随语料大小的增加而线性增长。在大型文本语料库上的实验证明了该方法的有效性和质量。  
**简介**  
从语料库中提取高质量短语，在很多领域中都是一个重要任务，如科研，新闻，社交媒体，企业等。在这些大型、动态的文档集合中，分析人员通常对可变长度的短语感兴趣，包括科学概念、事件、组织、产品、口号等。高效提取高质量的短语使大量应用程序能够从单词粒度转换到短语粒度。包括“topic tracking[21]”,"OLAP on multi-dimensional text collection[40]","docment categorization"等。短语的抽取对于信息抽取是至关重要的，因为许多概念、实体和关系都表现在短语中。这项工作的研究起源于NLP，但将NLP工具应用在偏离严格的语言规则的大数据上也是一个引人注目的挑战，如应用在查询日志、社交媒体消息、文本事物记录上等。因此研究者们一直在寻找更通用的数据驱动方法，主要是基于频繁模式挖掘原理（frequent pattern mining）[2,34]。早期的工作集中在有效地检索重复出现的单词序列，但是许多这样的序列并没有形成有意义的短语。最近的工作会根据基于频率的统计信息对它们进行筛选或排序。然而，数据的原始频率往往会产生误导性的质量评估，并且结果不令人满意，如下例所示。
